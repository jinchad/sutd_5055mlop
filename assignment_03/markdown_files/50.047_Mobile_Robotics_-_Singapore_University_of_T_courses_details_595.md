50.047_Mobile_Robotics_-_Singapore_University_of_T



50.047 Mobile Robotics
======================

The mobile robotics course is an introductory course on intelligent robots and systems. It is a course at the intersection of machine learning, artificial intelligence, computer vision and control theory. The course will introduce fundamentals of developing systems which can sense, plan and act in the world based on various topics from the aforementioned domains. The emphasis will be on algorithm design, probabilistic reasoning, decision making under uncertainty and learning to improve behaviours using data.

##### **Pre-requisite**

* Basic knowledge of Linear Algebra and Calculus
* ISTD students
  + [10.020 Data Driven World](/course/10-020-data-driven-world-elective/), and
  + [10.022 Modelling Uncertainty](/course/10-022-modelling-uncertainty), and
  + [50.001 Information Systems and Programming](/course/50-001-information-systems-programming/), and
  + [50.004 Algorithms](/course/50-004-algorithms/)
* Non-ISTD students
  + [10.020 Data Driven World](/course/10-020-data-driven-world-elective/), and
  + [10.022 Modelling Uncertainty](/course/10-022-modelling-uncertainty), and
  + [50.004 Algorithms](/course/50-004-algorithms/)
* Python/C++ Programming
* Linux OS (optional)

##### **Learning Objectives**

* **Introduction:** Basics of Linux, Robot Operating System, 3D Gazebo simulator, RViz robot visualizer.
* **Feedback Control and Planning:** how can we compute the commands that can bring a robotic system from its current state to a desired state?
* **Mapping:** how can we combine noisy measurements from sensors with the robot’s pose to build a map of the environment?
* **State Estimation and Localization:** the state of the robot is not always directly measurable/observable. How can we determine the relative weights of multiple sensor measurements in order to form an accurate estimate of the (hidden) state?
* **Geometry of Computer Vision:** how can modelling pixel projections on an RGB camera help us infer the 3D structure of the world? How can we triangulate points seen from two cameras? How can we estimate the camera’s pose (and therefore the robot’s) while it is moving in the environment?

##### **Measurable Outcomes**

1. Learn and implement algorithms through lectures and tutorial sessions.
2. Learn and implement state-of-the-art software development tools through lectures and tutorial sessions.
3. Develop and practice hands-on learning from lectures and tutorial sessions to solve real-world problems on virtual and physical robotic platforms.
4. Develop critical thinking and problem-solving skills through instructed lectures and tutorial sessions.

##### **Topics Covered**

1. Sensors and Actuators
2. Kinematics
3. Dynamics
4. Modelling and Control
5. Planning
6. Map Representations and Map Alignment
7. Occupancy Grid Mapping with Known Robot Poses
8. Bayesian Estimation
9. Kalman Filter
10. Particle Fiter
11. Robot Vision
12. Visual Odemetry and Visual SLAM
13. Planning under Uncertainty

##### **Textbook(s) and/or Other Required Material**

No required textbooks as notes will be provided. For further reading, we recommend

1. Probabilistic Robotics, by Thrun, Fox, and Burgard (PR in the outline)
2. Computational Principles of Mobile Robotics, 2nd edition, by Dudek and Jenkin
3. Planning Algorithms, by Lavalle
4. Robotics, Vision, and Control, by Corke
5. Introduction to Autonomous Mobile Robots, by Siegwart, Nourbakhsh, Scaramuzza

##### **Course Instructor(s)**

* [Prof Malika Meghani](/profile/malika-meghjani/)

Tags

[Term 7](/education/undergraduate/courses/?course-term=860)
[Elective / Technical Elective](/education/undergraduate/courses/?course-type=853)
[ISTD](/education/undergraduate/courses/?pillar-cluster=11)

